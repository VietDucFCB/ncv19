{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "2b32366c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "ade89ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_path = \"C:\\\\Users\\\\ASUS\\\\OneDrive\\\\Máy tính\\\\KHTN_HK2\\\\Covid_project\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "618ef3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_csv(load_file):\n",
    "    dataframe = pd.read_csv(load_file)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "417df29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_csv_position           = c_path + \"datasource\\\\position\\\\\"\n",
    "path_csv_time_series        = c_path + \"datasource\\\\time_series\"\n",
    "path_csv_position_Comfirmed = path_csv_position + \"time_series_Comfirmed\\\\\"\n",
    "path_csv_position_Death     = path_csv_position + \"time_series_Death\\\\\"\n",
    "path_csv_position_Recovered = path_csv_position + \"time_series_Recovered\\\\\"\n",
    "path_target                 = c_path + \"targetfile\\\\\"\n",
    "path_target_time_series     = path_target + \"time_series_target_file.csv\"\n",
    "path_targer_position_comfirmed = path_target + \"position_comfirmed_target_file.csv\"\n",
    "path_targer_position_death = path_target + \"position_death_target_file.csv\"\n",
    "path_targer_position_recovered = path_target + \"position_recovered_target_file.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "13b41cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(path_file):\n",
    "    target_raw = []\n",
    "    for csv_file in glob.glob(path_file + \"/*.csv\"):\n",
    "        data = extract_csv(csv_file)\n",
    "        target_raw.append(data)\n",
    "    extracted_file = pd.concat(target_raw, ignore_index = True)\n",
    "    return extracted_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "b60cdd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(csv_path, load_data):\n",
    "    load_data.to_csv(csv_path, index = False)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "01eeb9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(message):\n",
    "    time_format = '%H:%M:%S-%h-%d-%Y'\n",
    "    now = datetime.now() # get current timestamp\n",
    "    timestamp = now.strftime(time_format)\n",
    "    with open(\"logfile.txt\",\"a\") as f:\n",
    "        f.write(timestamp + ',' + message + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "a8143de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_csv_time_series(load_dataframe):\n",
    "    \n",
    "    for column in load_dataframe.columns:\n",
    "        if column != 'Province/State':\n",
    "            load_dataframe[column].fillna(0, inplace=True)\n",
    "\n",
    "    date_columns = ['Last Update'] # trans format time to Hour-Minute-Second-MonthName-Day-Year\n",
    "    for column in date_columns:\n",
    "        load_dataframe[column] = pd.to_datetime(load_dataframe[column], dayfirst=True).dt.strftime('%H:%M:%S-%h-%d-%Y')\n",
    "    \n",
    "    load_dataframe.drop(columns = ['Suspected', 'ConfnSusp', 'Notes'], inplace = True)\n",
    "    \n",
    "    # Del row Confirmed, Deaths, Recovered == 0\n",
    "    #load_dataframe = load_dataframe[~((df['Confirmed'] == 0) & (df['Deaths'] == 0) & (df['Recovered'] == 0))]\n",
    "    \n",
    "    load_dataframe.sort_values(by='Last Update', ascending=True, inplace=True)\n",
    "\n",
    "    return load_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "afbd45a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_position_comfirmed():\n",
    "    df1 = pd.read_csv(path_csv_position_Comfirmed + \"time_series_19-covid-Confirmed_archived_0325.csv\")\n",
    "    df2 = pd.read_csv(path_csv_position_Comfirmed + \"time_series_2019-ncov-Confirmed.csv\")\n",
    "\n",
    "    set1 = set(df1.columns)\n",
    "    set2 = set(df2.columns)\n",
    "\n",
    "    columns = list(set1 & set2)\n",
    "\n",
    "    for column in columns:\n",
    "        if column not in df1.columns:\n",
    "            df1.insert(-1, column, 0)\n",
    "        if column not in df2.columns:\n",
    "            df2.insert(-1, column, 0)  \n",
    "    \n",
    "    # combine data frame\n",
    "    combined_df = pd.concat([df1, df2], ignore_index=True)\n",
    "    dataframe = pd.DataFrame(combined_df)\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "5763561a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_position_Death():\n",
    "    df1 = pd.read_csv(path_csv_position_Death + \"time_series_19-covid-Deaths_archived_0325.csv\")\n",
    "    df2 = pd.read_csv(path_csv_position_Death + \"time_series_2019-ncov-Deaths.csv\")\n",
    "\n",
    "    set1 = set(df1.columns)\n",
    "    set2 = set(df2.columns)\n",
    "\n",
    "    columns = list(set1 & set2)\n",
    "\n",
    "    for column in columns:\n",
    "        if column not in df1.columns:\n",
    "            df1.insert(-1, column, 0)\n",
    "        if column not in df2.columns:\n",
    "            df2.insert(-1, column, 0)  \n",
    "    \n",
    "    # combine data frame\n",
    "    combined_df = pd.concat([df1, df2], ignore_index=True)\n",
    "    dataframe = pd.DataFrame(combined_df)\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "84df4e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_position_Recovered():\n",
    "    df1 = pd.read_csv(path_csv_position_Recovered + \"time_series_19-covid-Recovered_archived_0325.csv\")\n",
    "    df2 = pd.read_csv(path_csv_position_Recovered + \"time_series_2019-ncov-Recovered.csv\")\n",
    "\n",
    "    set1 = set(df1.columns)\n",
    "    set2 = set(df2.columns)\n",
    "\n",
    "    columns = list(set1 & set2)\n",
    "\n",
    "    for column in columns:\n",
    "        if column not in df1.columns:\n",
    "            df1.insert(-1, column, 0)\n",
    "        if column not in df2.columns:\n",
    "            df2.insert(-1, column, 0)  \n",
    "    \n",
    "    # combine data frame\n",
    "    combined_df = pd.concat([df1, df2], ignore_index=True)\n",
    "    dataframe = pd.DataFrame(combined_df)\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "e917de8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_csv_position(load_dataframe):\n",
    "    \n",
    "    for column in load_dataframe.columns:\n",
    "        if column != 'Province/State':\n",
    "            load_dataframe[column].fillna(0, inplace=True)\n",
    "    \n",
    "    new_column_names = []\n",
    "    for column in load_dataframe.columns:\n",
    "        if column not in ['Province/State', 'Country/Region', 'Lat', 'Long']:\n",
    "            new_name = pd.to_datetime(column, dayfirst=True).strftime('%H:%M:%S-%h-%d-%Y')\n",
    "            new_column_names.append(new_name)\n",
    "        else:\n",
    "            new_column_names.append(column)\n",
    "    load_dataframe.columns = new_column_names\n",
    "    \n",
    "    column_labels = load_dataframe.columns.tolist()\n",
    "    filtered_labels = [label for label in column_labels if label not in ['Province/State', 'Country/Region', 'Lat', 'Long']]\n",
    "\n",
    "    sorted_df = load_dataframe[filtered_labels].sort_index(axis=1)\n",
    "    \n",
    "    return load_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "35becf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "log(\"Extract file time series csv\")\n",
    "data_time_series = extract(path_csv_time_series)\n",
    "df_time_series = pd.DataFrame(data_time_series)\n",
    "log(\"Extracted file time series csv\")\n",
    "\n",
    "log(\"Transform time series csv file\")\n",
    "trans_file_time_series = transform_csv_time_series(df_time_series)\n",
    "log(\"Transformed time series csv file\")\n",
    "\n",
    "log(\"Load time series csv file\")\n",
    "load(path_target_time_series, trans_file_time_series)\n",
    "log(\"Loaded time series csv file\")\n",
    "\n",
    "log(\"Etract file position comfirmed csv\")\n",
    "data_pos_comfirmed = extract(path_csv_position_Comfirmed)\n",
    "log(\"Extracted file position comfirmed csv\")\n",
    "\n",
    "log(\"Extract file position death csv\")\n",
    "data_pos_death = extract(path_csv_position_Death)\n",
    "log(\"Extracted file position death csv\")\n",
    "\n",
    "log(\"Extract file position revovered csv\")\n",
    "data_pos_recovered = extract(path_csv_position_Recovered)\n",
    "log(\"Extracted file position recovered csv\")\n",
    "\n",
    "log(\"Transform position comfirmed csv file\")\n",
    "df_pos_comfirmed = pd.DataFrame(data_pos_comfirmed)\n",
    "trans_pos_comfirmed = transform_csv_position(df_pos_comfirmed)\n",
    "log(\"Transformed position comfirmed csv file\")\n",
    "\n",
    "log(\"Transform position death csv file\")\n",
    "df_pos_death = pd.DataFrame(data_pos_death)\n",
    "trans_pos_death = transform_csv_position(df_pos_death)\n",
    "log(\"Transformed position death csv file\")\n",
    "\n",
    "log(\"Transform position recovered csv file\")\n",
    "df_pos_recovered = pd.DataFrame(data_pos_recovered)\n",
    "trans_pos_recovered = transform_csv_position(df_pos_recovered)\n",
    "log(\"Transformed position recovered csv file\")\n",
    "\n",
    "log(\"Load position confirmed csv file\")\n",
    "load(path_targer_position_comfirmed, trans_pos_comfirmed)\n",
    "log(\"Loaded position confirmed csv file\")\n",
    "\n",
    "log(\"Load position death csv file\")\n",
    "load(path_targer_position_death, trans_pos_death)\n",
    "log(\"Loaded position death csv file\")\n",
    "\n",
    "log(\"Load position recovered csv file\")\n",
    "load(path_targer_position_recovered, trans_pos_recovered)\n",
    "log(\"Loaded position recovered csv file\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
